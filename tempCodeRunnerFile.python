from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ExponentialLR
from tqdm.auto import tqdm
import torch
from timeit import default_timer as timer
import requests
from pathlib import Path
import os
from PIL import Image

if Path("helper_functions.py").is_file():
    print("helper_functions.py already exists, skipping download")
else:
    print("Downloading helper_functions.py")
    request = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py")
    with open("helper_functions.py", "wb") as f:
        f.write(request.content)
from helper_functions import accuracy_fn

# Set device
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

def load_images_with_labels(data_dir, batch_size, transform=None):
    """Loads images from a folder into a DataLoader with image names as labels.

    Args:
        data_dir (str): Path to the data directory.
        batch_size (int): Batch size for the DataLoader.
        transform (torchvision.transforms.Compose, optional): Data transformations. Defaults to None.

    Returns:
        torch.utils.data.DataLoader: A DataLoader instance.
    """

    if transform is None:
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor()
        ])

    image_paths = []
    for root, _, files in os.walk(data_dir):
        for file in files:
            if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png'):
                image_path = os.path.join(root, file)
                image_paths.append(image_path)

    class ImageDataset(Dataset):
        def __init__(self, image_paths, transform=None):
            self.image_paths = image_paths
            self.transform = transform

        def __getitem__(self, index):
            image_path = self.image_paths[index]
            image = Image.open(image_path).convert("RGB")
            if self.transform:
                image = self.transform(image)
            return image, image_path.split('/')[-1]  # Use filename as label

        def __len__(self):
            return len(self.image_paths)

    dataset = ImageDataset(image_paths, transform=transform)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    return dataloader

# Load images
path = 'D:\\image_folder\\Images'
image_list = load_images_with_labels(path, batch_size=1)
print(f"Loaded {len(image_list)} images.")

def extract_labels_from_dataloader(dataloader):
    """Extracts labels from a DataLoader and creates a list of labels.

    Args:
        dataloader (torch.utils.data.DataLoader): The DataLoader containing data and labels.

    Returns:
        list: A list of labels extracted from the DataLoader.
    """

    labels = []
    for _, label in dataloader:
        labels.append(label)
    return labels

# Extract labels
labels_list = extract_labels_from_dataloader(image_list)

for item in labels_list:
    print(item)

def extract_patches_from_dataloader(dataloader, patch_size):
    """Extracts patches from images in a DataLoader.

    Args:
        dataloader (torch.utils.data.DataLoader): DataLoader containing images.
        patch_size (int): Size of the patches.

    Returns:
        list: A list of image patches.
    """

    all_patches = []
    for images, labels in dataloader:
        for image in images:
            _, h, w = image.shape
            for i in range(0, h, patch_size):
                for j in range(0, w, patch_size):
                    patch = image[:, i:i+patch_size, j:j+patch_size]
                    if patch.shape[1] == patch_size and patch.shape[2] == patch_size:  # Ensure patch size is consistent
                        all_patches.append(patch)
    return all_patches

# Extract patches
patch_list = extract_patches_from_dataloader(image_list, patch_size=32)
print(f"Extracted {len(patch_list)} patches.")

def create_patch_dataloader_with_labels(patches, labels, batch_size=49):
    """Creates a DataLoader for image patches with corresponding labels.

    Args:
        patches (list): List of image patches.
        labels (list): List of labels, where each label corresponds to 49 patches.
        batch_size (int): Batch size (default: 49 patches).

    Returns:
        torch.utils.data.DataLoader: A DataLoader for image patches with labels.
    """

    assert len(patches) % batch_size == 0, "Number of patches must be divisible by batch size"
    assert len(labels) == len(patches) // batch_size, "Number of labels must match number of patches"

    class PatchDatasetWithLabels(Dataset):
        def __init__(self, patches, labels):
            self.patches = patches
            self.labels = labels

        def __getitem__(self, index):
            start_idx = index * batch_size
            end_idx = start_idx + batch_size
            patches_batch = self.patches[start_idx:end_idx]
            label = self.labels[index]
            return torch.stack(patches_batch), label

        def __len__(self):
            return len(self.labels)

    dataset = PatchDatasetWithLabels(patches, labels)
    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)
    return dataloader

# Create patch DataLoader
patch_loader = create_patch_dataloader_with_labels(patch_list, labels_list)
print(f"Created patch DataLoader with {len(patch_loader)} batches.")

for (X, y) in patch_loader:
    print(f"y===={X.shape}")

# Define the PDN model
class PDN(nn.Module):
    def __init__(self):
        super(PDN, self).__init__()

        # Encoder layers
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # Input channels: 3 (RGB), output: 32 channels
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),

            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
        )

        # Decoder layers (use transposed convolutions for upsampling)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),

            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),

            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),

            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid()  # Output layer between 0 and 1 for image reconstruction
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# Set random seed
torch.manual_seed(42)

# Initialize model, optimizer, and loss function
PDN_model = PDN().to(device)

feature_extrection_epoches = 20
PDN_network_epoches = 10

optimizer = optim.Adam(PDN_model.parameters(), lr=0.001)
scheduler = ExponentialLR(optimizer, gamma=0.97)

loss_fn = nn.MSELoss()  # Use MSELoss for reconstruction tasks

# Define train step function
def train_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               device: torch.device = device):
    train_loss = 0
    model.train()
    for batch, (X, _) in enumerate(data_loader):
        X = X.squeeze(0)  # Remove batch dimension since it's always 1
        X = X.to(device)

        # Forward pass
        y_pred = model(X)

        # Calculate loss
        loss = loss_fn(y_pred, X)
        train_loss += loss.item()

        # Optimizer zero grad
        optimizer.zero_grad()

        # Loss backward
        loss.backward()

        # Optimizer step
        optimizer.step()

    train_loss /= len(data_loader)
    print(f"Train loss: {train_loss:.5f}")

# Training loop
train_time_start_on_cpu = timer()

for epoch in tqdm(range(feature_extrection_epoches)):
    print(f"Epoch number: {epoch+1}")
    train_step(model=PDN_model, data_loader=patch_loader, optimizer=optimizer, loss_fn=loss_fn)

# Save the model
torch.save(PDN_model.state_dict(), 'pdn_model.pth')

print(f"Training complete. Model saved as 'pdn_model.pth'.")
